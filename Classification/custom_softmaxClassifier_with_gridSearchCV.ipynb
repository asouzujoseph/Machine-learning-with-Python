{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "custom_softmaxClassifier_with_gridSearchCV.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-IQC08GMV_f0"
      },
      "outputs": [],
      "source": [
        "# === NOTEBOOK & IMPORT SETUP ===\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "import random\n",
        "random.seed(50)\n",
        "\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "print(f\"X_train.shape = {X_train.shape}\") # 60,000 training images, 28x28 pixel arrays\n",
        "print(f\"y_train.shape = {y_train.shape}\") # 60,000 labels for the training images\n",
        "print(f\"X_test.shape = {X_test.shape}\") # 10,000 test images, 28x28 pixel arrays\n",
        "print(f\"y_test.shape = {y_test.shape}\") # 10,000 test labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOhhQhKGWp-6",
        "outputId": "775e0a5a-5297-4991-a6be-f086ef349bef"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train.shape = (60000, 28, 28)\n",
            "y_train.shape = (60000,)\n",
            "X_test.shape = (10000, 28, 28)\n",
            "y_test.shape = (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_features = 28 * 28\n",
        "\n",
        "X_train = X_train.reshape(-1, num_features)\n",
        "X_test = X_test.reshape(-1, num_features) # -1 means unspecified\n",
        "\n",
        "print(f\"X_train.shape = {X_train.shape}\") # 60,000 images, 28x28 pixel arrays\n",
        "print(f\"y_train.shape = {y_train.shape}\") # 60,000 labels\n",
        "print(f\"X_test.shape = {X_test.shape}\") # 10,000 test images, 28x28 pixel arrays\n",
        "print(f\"y_test.shape = {y_test.shape}\") # 10,000 test labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sJnMjYSWDZu",
        "outputId": "b0e9e8a4-ab45-4178-f70b-3214fe2835a7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train.shape = (60000, 784)\n",
            "y_train.shape = (60000,)\n",
            "X_test.shape = (10000, 784)\n",
            "y_test.shape = (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(np.unique(y_train))\n",
        "print(f\"There are {num_classes} different classes\")\n",
        "\n",
        "# dictionary\n",
        "# you can use this to convert a numerical label back into \n",
        "# the description of what it represents\n",
        "label_mapping = {\n",
        "    0: \"T-shirt/top\", \n",
        "    1: \"Trouser\", \n",
        "    2: \"Pullover\", \n",
        "    3: \"Dress\",\n",
        "    4: \"Coat\",\n",
        "    5: \"Sandal\",\n",
        "    6: \"Shirt\",\n",
        "    7: \"Sneaker\",\n",
        "    8: \"Bag\",\n",
        "    9: \"Ankle Boot\",\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSm6mo9bWZrN",
        "outputId": "9c97f401-3920-4dea-b790-e9a1f131ed0c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 10 different classes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.c_[np.ones([len( X_train), 1]),  X_train]\n",
        "X_test = np.c_[np.ones([len( X_test), 1]),  X_test]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "XX_train,validation_train, yy_train,validation_test = train_test_split( X_train, y_train, test_size=0.2)"
      ],
      "metadata": {
        "id": "5r-i5cd-WnvN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "### Helper functions\n",
        "def oneHotter(y):\n",
        "    n_classes = y.max() + 1\n",
        "    m = len(y)\n",
        "    Y_one_hot = np.zeros((m, n_classes))\n",
        "    Y_one_hot[np.arange(m), y] = 1\n",
        "    return Y_one_hot\n",
        "\n",
        "def softmax(s):\n",
        "  s -= np.max(s)\n",
        "  sm = (np.exp(s).T / np.sum(np.exp(s),axis=1)).T\n",
        "  return sm\n",
        "\n",
        "def learning_schedule(t, t0=5, t1=50):\n",
        "    return t0 / (t + t1)\n",
        "\n",
        "def custom_softmax(X,y):\n",
        "  m = X.shape[0]\n",
        "  n = X.shape[1]\n",
        "  k = len(np.unique(y))\n",
        "  theta = np.random.randn(n,k)\n",
        "  losses = []\n",
        "  thetas = []\n",
        "  grads = []\n",
        "  g_bias = []\n",
        "  g_theta = []\n",
        "\n",
        "  y_hot = oneHotter(y)\n",
        "  s = X@theta\n",
        "  prob = softmax(s)\n",
        "  gradient = (-1/m)*X.T@(y_hot-prob)\n",
        "  theta = theta - gradient\n",
        "  loss = (-1/m)*np.sum(y_hot * np.log(prob), axis=1)\n",
        "  losses.append(loss)\n",
        "  thetas.append(theta)\n",
        "  grads.append(gradient)\n",
        "  g_bias.append(gradients[0][0])\n",
        "  g_theta.append(gradients[1][0])\n"
      ],
      "metadata": {
        "id": "prQrhysqW6o7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}